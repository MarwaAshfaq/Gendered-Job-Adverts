{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549f9c92-1013-4e13-a9ce-de46950bb10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SECOND STAGE FILTER - REFINE ANALYTICAL JOBS\n",
      "======================================================================\n",
      "This tool applies advanced scoring to identify the most relevant\n",
      "analytical, research, and data science positions.\n",
      "======================================================================\n",
      "Input file: C:\\Users\\HP\\OneDrive - University of Southampton\\Documents\\Dissertation Project - Marwa Ashfaq\\Dataset\\50K_jobs_filtered.xlsx\n",
      "Output file: C:\\Users\\HP\\OneDrive - University of Southampton\\Documents\\Dissertation Project - Marwa Ashfaq\\Dataset\\50K_jobs_highly_relevant.xlsx\n",
      "Loaded filtered dataset: 2,434 jobs\n",
      "Columns: ['category', 'city', 'company_name', 'geo', 'job_board', 'job_description', 'job_requirements', 'job_title', 'job_type', 'post_date', 'salary_offered', 'state', 'keywords_found', 'filter_date']\n",
      "\n",
      "Dataset overview:\n",
      "Total jobs: 2,434\n",
      "Sample job titles:\n",
      "  - Business Manager - Lexus \n",
      "  - Supply Chain Business Analyst\n",
      "  - SQL Insight Analyst\n",
      "  - Production Design Engineer\n",
      "  - HR Advisor\n",
      "  - HRIS Analyst - Move Into Workday - Work From Home\n",
      "  - Design Estimator\n",
      "  - Tax Specialist - Private Client\n",
      "  - Senior Conference Producer - Oil & Gas\n",
      "  - CNC Setter 3 Shift Rotaing\n",
      "\n",
      "Starting relevance scoring...\n",
      "\n",
      "Applying second-stage filtering...\n",
      "Minimum relevance score: 3\n",
      "Processed 0 of 2,434 jobs...\n",
      "Processed 500 of 2,434 jobs...\n",
      "Processed 1,000 of 2,434 jobs...\n",
      "Processed 1,500 of 2,434 jobs...\n",
      "Processed 2,000 of 2,434 jobs...\n",
      "\n",
      "Second-stage filtering complete!\n",
      "Original filtered jobs: 2,434\n",
      "Highly relevant jobs (score >= 3): 1,053\n",
      "Further reduction: 1,381 jobs removed\n",
      "Final percentage: 43.3%\n",
      "\n",
      "============================================================\n",
      "RELEVANCE SCORE DISTRIBUTION\n",
      "============================================================\n",
      "Score 3: 205 jobs\n",
      "Score 4: 242 jobs\n",
      "Score 5: 181 jobs\n",
      "Score 6: 127 jobs\n",
      "Score 7: 64 jobs\n",
      "Score 8: 60 jobs\n",
      "Score 9: 38 jobs\n",
      "Score 10: 28 jobs\n",
      "Score 11: 17 jobs\n",
      "Score 12: 25 jobs\n",
      "Score 13: 6 jobs\n",
      "Score 14: 11 jobs\n",
      "Score 15: 9 jobs\n",
      "Score 16: 4 jobs\n",
      "Score 17: 8 jobs\n",
      "Score 18: 9 jobs\n",
      "Score 19: 1 jobs\n",
      "Score 20: 3 jobs\n",
      "Score 22: 4 jobs\n",
      "Score 23: 8 jobs\n",
      "Score 24: 2 jobs\n",
      "Score 25: 1 jobs\n",
      "\n",
      "Average score: 6.12\n",
      "Median score: 5.00\n",
      "Max score: 25\n",
      "\n",
      "============================================================\n",
      "TOP 10 HIGHEST-SCORING JOBS\n",
      "============================================================\n",
      "\n",
      "Score: 25\n",
      "Title: Big Data Scientist\n",
      "Company: Vodafone \n",
      "Reasons: advanced_analytics: data scientist; advanced_analytics: machine learning; advanced_analytics: artifi...\n",
      "\n",
      "Score: 24\n",
      "Title: Data Scientist / AI Engineer\n",
      "Company: Deerfoot IT Resources Ltd \n",
      "Reasons: advanced_analytics: data scientist; advanced_analytics: machine learning; advanced_analytics: artifi...\n",
      "\n",
      "Score: 24\n",
      "Title: Data Scientist / Data Analytics Solution Consultant - Digital Finance\n",
      "Company: Edengrove \n",
      "Reasons: advanced_analytics: data scientist; advanced_analytics: artificial intelligence; advanced_analytics:...\n",
      "\n",
      "Score: 23\n",
      "Title: Lead Data Scientist\n",
      "Company: Harnham \n",
      "Reasons: advanced_analytics: data scientist; advanced_analytics: machine learning; advanced_analytics: artifi...\n",
      "\n",
      "Score: 23\n",
      "Title: Lead Data Scientist\n",
      "Company: Harnham \n",
      "Reasons: advanced_analytics: data scientist; advanced_analytics: machine learning; advanced_analytics: artifi...\n",
      "\n",
      "Score: 23\n",
      "Title: Quantitative Services Market Risk Senior Data Analyst\n",
      "Company: Bank of America \n",
      "Reasons: advanced_analytics: machine learning; advanced_analytics: data mining; advanced_analytics: big data;...\n",
      "\n",
      "Score: 23\n",
      "Title: Quantitative Services Market Risk Senior Data Analyst\n",
      "Company: Bank of America \n",
      "Reasons: advanced_analytics: machine learning; advanced_analytics: data mining; advanced_analytics: big data;...\n",
      "\n",
      "Score: 23\n",
      "Title: Senior Pricing Analyst\n",
      "Company: Lowell Group \n",
      "Reasons: operations_research: or analyst; operations_research: decision science; operations_research: managem...\n",
      "\n",
      "Score: 23\n",
      "Title: Lead Data Scientist\n",
      "Company: Harnham \n",
      "Reasons: advanced_analytics: data scientist; advanced_analytics: machine learning; advanced_analytics: artifi...\n",
      "\n",
      "Score: 23\n",
      "Title: Lead Data Scientist\n",
      "Company: Harnham \n",
      "Reasons: advanced_analytics: data scientist; advanced_analytics: machine learning; advanced_analytics: artifi...\n",
      "\n",
      "============================================================\n",
      "SCORE THRESHOLD ADJUSTMENT\n",
      "============================================================\n",
      "Current results with score >= 3: 1,053 jobs\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to try a different minimum score? (y/n):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Refined data saved to: C:\\Users\\HP\\OneDrive - University of Southampton\\Documents\\Dissertation Project - Marwa Ashfaq\\Dataset\\50K_jobs_highly_relevant.xlsx\n",
      "\n",
      "======================================================================\n",
      "SECOND-STAGE FILTERING COMPLETED!\n",
      "======================================================================\n",
      "Original filtered jobs: 2,434\n",
      "Highly relevant jobs: 1,053\n",
      "Final reduction: 56.7%\n",
      "Quality improvement: Higher concentration of analytical roles\n",
      "Saved to: C:\\Users\\HP\\OneDrive - University of Southampton\\Documents\\Dissertation Project - Marwa Ashfaq\\Dataset\\50K_jobs_highly_relevant.xlsx\n",
      "\n",
      "Top categories in refined results:\n",
      "  banking jobs: 159\n",
      "  it jobs: 119\n",
      "  construction property jobs: 115\n",
      "  strategy consultancy jobs: 107\n",
      "  marketing jobs: 97\n",
      "  science jobs: 59\n",
      "  graduate training internships jobs: 57\n",
      "  finance jobs: 47\n",
      "  accountancy qualified jobs: 43\n",
      "  energy jobs: 29\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "class SecondStageJobFilter:\n",
    "    def __init__(self):\n",
    "        # HIGH-VALUE keywords that indicate truly relevant analytical roles\n",
    "        self.high_value_keywords = {\n",
    "            'operations_research': [\n",
    "                'operations research', 'operational research', 'or analyst', 'or specialist',\n",
    "                'optimization', 'linear programming', 'mathematical modeling', 'mathematical modelling',\n",
    "                'supply chain optimization', 'logistics optimization', 'decision science',\n",
    "                'management science', 'operational analytics', 'process optimization'\n",
    "            ],\n",
    "            'advanced_analytics': [\n",
    "                'data scientist', 'machine learning', 'artificial intelligence', 'ai specialist',\n",
    "                'predictive analytics', 'statistical modeling', 'statistical modelling',\n",
    "                'data mining', 'big data', 'advanced analytics', 'quantitative analysis',\n",
    "                'econometrics', 'biostatistics', 'statistical analysis'\n",
    "            ],\n",
    "            'business_intelligence': [\n",
    "                'business intelligence', 'bi analyst', 'data analyst', 'business analyst',\n",
    "                'reporting analyst', 'analytics manager', 'insights analyst',\n",
    "                'performance analyst', 'commercial analyst', 'strategy analyst',\n",
    "                'planning analyst', 'research analyst', 'market research analyst'\n",
    "            ],\n",
    "            'financial_analytics': [\n",
    "                'quantitative analyst', 'quant', 'risk analyst', 'credit analyst',\n",
    "                'financial analyst', 'investment analyst', 'portfolio analyst',\n",
    "                'actuarial analyst', 'pricing analyst', 'financial modeller',\n",
    "                'credit risk analyst', 'market risk analyst', 'operational risk analyst'\n",
    "            ],\n",
    "            'research_roles': [\n",
    "                'research scientist', 'researcher', 'research associate', 'research manager',\n",
    "                'market researcher', 'user researcher', 'ux researcher', 'policy researcher',\n",
    "                'graduate researcher', 'research director', 'research executive'\n",
    "            ],\n",
    "            'consulting_analytics': [\n",
    "                'management consultant', 'strategy consultant', 'analytics consultant',\n",
    "                'business consultant', 'data consultant', 'consulting analyst',\n",
    "                'management science consultant', 'operational consultant'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Combine all high-value keywords\n",
    "        self.all_high_value = []\n",
    "        for category, keywords in self.high_value_keywords.items():\n",
    "            self.all_high_value.extend(keywords)\n",
    "        \n",
    "        # REFINED exclusions - jobs that shouldn't be in analytical dataset\n",
    "        self.refined_exclusions = [\n",
    "            # Basic administrative roles\n",
    "            'hr administrator', 'hr assistant', 'hr advisor', 'hr coordinator',\n",
    "            'office administrator', 'administration assistant', 'admin coordinator',\n",
    "            'executive assistant', 'personal assistant', 'office manager',\n",
    "            \n",
    "            # Basic customer service\n",
    "            'customer service', 'customer advisor', 'customer support', 'client services',\n",
    "            'customer success', 'account coordinator', 'client coordinator',\n",
    "            \n",
    "            # Basic sales/marketing\n",
    "            'sales executive', 'sales manager', 'sales advisor', 'sales representative',\n",
    "            'marketing executive', 'marketing assistant', 'marketing coordinator',\n",
    "            'business development executive', 'account executive',\n",
    "            \n",
    "            # Basic finance/accounting (non-analytical)\n",
    "            'accounts assistant', 'accounts clerk', 'bookkeeper', 'finance assistant',\n",
    "            'payroll administrator', 'credit controller', 'billing coordinator',\n",
    "            'accounts payable', 'accounts receivable', 'purchase ledger',\n",
    "            \n",
    "            # Basic IT/technical support\n",
    "            'it support', 'technical support', 'help desk', 'desktop support',\n",
    "            'system administrator', 'network administrator', 'it administrator',\n",
    "            \n",
    "            # Basic operations\n",
    "            'operations coordinator', 'operations assistant', 'logistics coordinator',\n",
    "            'supply chain coordinator', 'procurement coordinator',\n",
    "            \n",
    "            # Basic recruitment/HR\n",
    "            'recruitment administrator', 'recruitment coordinator', 'talent coordinator',\n",
    "            'resourcing specialist', 'hr generalist', 'hr business partner',\n",
    "            \n",
    "            # Non-analytical legal\n",
    "            'legal assistant', 'legal secretary', 'legal administrator', 'compliance officer',\n",
    "            'regulatory officer', 'legal coordinator',\n",
    "            \n",
    "            # Basic project roles\n",
    "            'project coordinator', 'project administrator', 'program coordinator',\n",
    "            'project assistant', 'program assistant'\n",
    "        ]\n",
    "        \n",
    "        # Advanced exclusion patterns\n",
    "        self.advanced_exclusion_patterns = [\n",
    "            r'\\btrainee\\s+(?!data|analyst|research)', # Trainee roles except data/analyst/research\n",
    "            r'\\bgraduate\\s+(?!data|analyst|research|statistician)', # Graduate roles except analytical\n",
    "            r'\\bjunior\\s+(?!data|analyst|research)', # Junior roles except analytical\n",
    "            r'\\bassistant\\s+(?!research|data)', # Assistant roles except research/data\n",
    "            r'\\bcoordinator\\s+(?!research|data|analytics)', # Coordinator except analytical\n",
    "            r'\\badministrator\\s+(?!data|database)', # Administrator except data-related\n",
    "            r'\\bsupport\\s+(?!analyst|research|data)', # Support roles except analytical\n",
    "            r'\\bspecialist\\s+(?!data|research|analytics|risk|credit)', # Specialist except analytical\n",
    "            r'\\bofficer\\s+(?!research|data|analytics|risk)', # Officer except analytical\n",
    "        ]\n",
    "\n",
    "    def load_filtered_dataset(self, file_path):\n",
    "        \"\"\"Load the already filtered dataset\"\"\"\n",
    "        try:\n",
    "            df = pd.read_excel(file_path)\n",
    "            print(f\"Loaded filtered dataset: {len(df):,} jobs\")\n",
    "            print(f\"Columns: {list(df.columns)}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading dataset: {e}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_relevance_score(self, job_title, job_description, job_requirements):\n",
    "        \"\"\"Calculate a relevance score for each job\"\"\"\n",
    "        score = 0\n",
    "        reasons = []\n",
    "        \n",
    "        # Combine all text for analysis\n",
    "        combined_text = f\"{job_title or ''} {job_description or ''} {job_requirements or ''}\".lower()\n",
    "        \n",
    "        # High-value keyword scoring\n",
    "        for category, keywords in self.high_value_keywords.items():\n",
    "            category_matches = 0\n",
    "            for keyword in keywords:\n",
    "                if keyword in combined_text:\n",
    "                    category_matches += 1\n",
    "                    reasons.append(f\"{category}: {keyword}\")\n",
    "            \n",
    "            # Score based on category importance\n",
    "            if category == 'operations_research':\n",
    "                score += category_matches * 5  # Highest priority\n",
    "            elif category == 'advanced_analytics':\n",
    "                score += category_matches * 4\n",
    "            elif category == 'financial_analytics':\n",
    "                score += category_matches * 3\n",
    "            elif category == 'business_intelligence':\n",
    "                score += category_matches * 2\n",
    "            elif category in ['research_roles', 'consulting_analytics']:\n",
    "                score += category_matches * 2\n",
    "        \n",
    "        # Bonus for job title relevance\n",
    "        title_lower = (job_title or '').lower()\n",
    "        high_value_title_keywords = [\n",
    "            'analyst', 'scientist', 'researcher', 'quant', 'statistician',\n",
    "            'econometrician', 'consultant', 'manager', 'director', 'lead'\n",
    "        ]\n",
    "        \n",
    "        for keyword in high_value_title_keywords:\n",
    "            if keyword in title_lower:\n",
    "                score += 2\n",
    "                reasons.append(f\"title: {keyword}\")\n",
    "        \n",
    "        # Penalty for refined exclusions\n",
    "        for exclusion in self.refined_exclusions:\n",
    "            if exclusion in combined_text:\n",
    "                score -= 3\n",
    "                reasons.append(f\"PENALTY: {exclusion}\")\n",
    "        \n",
    "        # Penalty for advanced exclusion patterns\n",
    "        for pattern in self.advanced_exclusion_patterns:\n",
    "            if re.search(pattern, combined_text):\n",
    "                score -= 2\n",
    "                match = re.search(pattern, combined_text).group()\n",
    "                reasons.append(f\"PENALTY: {match}\")\n",
    "        \n",
    "        return max(0, score), reasons  # Don't allow negative scores\n",
    "\n",
    "    def apply_second_filter(self, df, min_score=3):\n",
    "        \"\"\"Apply second stage filtering with scoring\"\"\"\n",
    "        print(f\"\\nApplying second-stage filtering...\")\n",
    "        print(f\"Minimum relevance score: {min_score}\")\n",
    "        \n",
    "        # Calculate relevance scores\n",
    "        scores = []\n",
    "        score_reasons = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            if idx % 500 == 0:\n",
    "                print(f\"Processed {idx:,} of {len(df):,} jobs...\")\n",
    "            \n",
    "            job_title = row.get('job_title', '')\n",
    "            job_description = row.get('job_description', '')\n",
    "            job_requirements = row.get('job_requirements', '')\n",
    "            \n",
    "            score, reasons = self.calculate_relevance_score(job_title, job_description, job_requirements)\n",
    "            scores.append(score)\n",
    "            score_reasons.append('; '.join(reasons) if reasons else 'No specific matches')\n",
    "        \n",
    "        # Add scores to dataframe\n",
    "        df['relevance_score'] = scores\n",
    "        df['score_reasons'] = score_reasons\n",
    "        df['second_filter_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Filter based on minimum score\n",
    "        highly_relevant_df = df[df['relevance_score'] >= min_score].copy()\n",
    "        \n",
    "        print(f\"\\nSecond-stage filtering complete!\")\n",
    "        print(f\"Original filtered jobs: {len(df):,}\")\n",
    "        print(f\"Highly relevant jobs (score >= {min_score}): {len(highly_relevant_df):,}\")\n",
    "        print(f\"Further reduction: {len(df) - len(highly_relevant_df):,} jobs removed\")\n",
    "        print(f\"Final percentage: {len(highly_relevant_df)/len(df)*100:.1f}%\")\n",
    "        \n",
    "        return highly_relevant_df\n",
    "\n",
    "    def show_score_distribution(self, df):\n",
    "        \"\"\"Show distribution of relevance scores\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"RELEVANCE SCORE DISTRIBUTION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        score_counts = df['relevance_score'].value_counts().sort_index()\n",
    "        for score, count in score_counts.items():\n",
    "            print(f\"Score {score}: {count:,} jobs\")\n",
    "        \n",
    "        print(f\"\\nAverage score: {df['relevance_score'].mean():.2f}\")\n",
    "        print(f\"Median score: {df['relevance_score'].median():.2f}\")\n",
    "        print(f\"Max score: {df['relevance_score'].max()}\")\n",
    "\n",
    "    def show_top_jobs(self, df, n=10):\n",
    "        \"\"\"Show top-scoring jobs\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"TOP {n} HIGHEST-SCORING JOBS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        top_jobs = df.nlargest(n, 'relevance_score')[['job_title', 'company_name', 'relevance_score', 'score_reasons']]\n",
    "        \n",
    "        for idx, row in top_jobs.iterrows():\n",
    "            print(f\"\\nScore: {row['relevance_score']}\")\n",
    "            print(f\"Title: {row['job_title']}\")\n",
    "            print(f\"Company: {row['company_name']}\")\n",
    "            print(f\"Reasons: {row['score_reasons'][:100]}...\")\n",
    "\n",
    "    def save_refined_data(self, df, output_path):\n",
    "        \"\"\"Save the refined dataset\"\"\"\n",
    "        try:\n",
    "            # Sort by relevance score (highest first)\n",
    "            df_sorted = df.sort_values('relevance_score', ascending=False)\n",
    "            \n",
    "            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "                df_sorted.to_excel(writer, sheet_name='Highly_Relevant_Jobs', index=False)\n",
    "            \n",
    "            print(f\"\\nRefined data saved to: {output_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving refined data: {e}\")\n",
    "            return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for second-stage filtering\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"SECOND STAGE FILTER - REFINE ANALYTICAL JOBS\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"This tool applies advanced scoring to identify the most relevant\")\n",
    "    print(\"analytical, research, and data science positions.\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Pre-configured paths\n",
    "    input_path = r\"C:\\Users\\HP\\OneDrive - University of Southampton\\Documents\\Dissertation Project - Marwa Ashfaq\\Dataset\\50K_jobs_filtered.xlsx\"\n",
    "    output_path = r\"C:\\Users\\HP\\OneDrive - University of Southampton\\Documents\\Dissertation Project - Marwa Ashfaq\\Dataset\\50K_jobs_highly_relevant.xlsx\"\n",
    "    \n",
    "    print(f\"Input file: {input_path}\")\n",
    "    print(f\"Output file: {output_path}\")\n",
    "    \n",
    "    # Initialize filter\n",
    "    filter_tool = SecondStageJobFilter()\n",
    "    \n",
    "    # Load filtered dataset\n",
    "    df = filter_tool.load_filtered_dataset(input_path)\n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    # Show current dataset info\n",
    "    print(f\"\\nDataset overview:\")\n",
    "    print(f\"Total jobs: {len(df):,}\")\n",
    "    if 'job_title' in df.columns:\n",
    "        print(f\"Sample job titles:\")\n",
    "        for title in df['job_title'].head(10):\n",
    "            print(f\"  - {title}\")\n",
    "    \n",
    "    # Apply second-stage filtering with scoring\n",
    "    print(f\"\\nStarting relevance scoring...\")\n",
    "    refined_df = filter_tool.apply_second_filter(df, min_score=3)\n",
    "    \n",
    "    # Show score distribution\n",
    "    filter_tool.show_score_distribution(refined_df)\n",
    "    \n",
    "    # Show top jobs\n",
    "    filter_tool.show_top_jobs(refined_df)\n",
    "    \n",
    "    # Ask if user wants to adjust the minimum score\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"SCORE THRESHOLD ADJUSTMENT\")\n",
    "    print(\"=\"*60)\n",
    "    current_count = len(refined_df)\n",
    "    print(f\"Current results with score >= 3: {current_count:,} jobs\")\n",
    "    \n",
    "    adjust = input(\"Do you want to try a different minimum score? (y/n): \").strip().lower()\n",
    "    \n",
    "    if adjust in ['y', 'yes']:\n",
    "        try:\n",
    "            new_score = int(input(\"Enter new minimum score (1-10): \"))\n",
    "            if 1 <= new_score <= 10:\n",
    "                refined_df = df[df['relevance_score'] >= new_score].copy()\n",
    "                print(f\"New results with score >= {new_score}: {len(refined_df):,} jobs\")\n",
    "            else:\n",
    "                print(\"Invalid score. Using original results.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Using original results.\")\n",
    "    \n",
    "    # Save refined data\n",
    "    if len(refined_df) > 0:\n",
    "        success = filter_tool.save_refined_data(refined_df, output_path)\n",
    "        \n",
    "        if success:\n",
    "            print(\"\\n\" + \"=\"*70)\n",
    "            print(\"SECOND-STAGE FILTERING COMPLETED!\")\n",
    "            print(\"=\"*70)\n",
    "            print(f\"Original filtered jobs: {len(df):,}\")\n",
    "            print(f\"Highly relevant jobs: {len(refined_df):,}\")\n",
    "            print(f\"Final reduction: {((len(df) - len(refined_df))/len(df)*100):.1f}%\")\n",
    "            print(f\"Quality improvement: Higher concentration of analytical roles\")\n",
    "            print(f\"Saved to: {output_path}\")\n",
    "            \n",
    "            # Show category breakdown if available\n",
    "            if 'category' in refined_df.columns:\n",
    "                print(f\"\\nTop categories in refined results:\")\n",
    "                category_counts = refined_df['category'].value_counts().head(10)\n",
    "                for category, count in category_counts.items():\n",
    "                    print(f\"  {category}: {count}\")\n",
    "        else:\n",
    "            print(\"Failed to save refined data.\")\n",
    "    else:\n",
    "        print(\"No jobs met the minimum score criteria. Try lowering the minimum score.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1746e-60ff-485c-a98e-7a8e078ac6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
