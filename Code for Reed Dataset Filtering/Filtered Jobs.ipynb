{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b164c900-838b-4d6b-aeb3-f18831908da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "UK JOBS DATASET FILTER - RELEVANT JOBS EXTRACTOR\n",
      "======================================================================\n",
      "This tool filters large job datasets to find relevant positions\n",
      "for Operations Research, Data Science, and Analytics roles.\n",
      "======================================================================\n",
      "Input file: C:\\Users\\HP\\OneDrive - University of Southampton\\Documents\\Dissertation Project - Marwa Ashfaq\\Dataset\\50K jobs_filtered.xlsx\n",
      "Output file: C:\\Users\\HP\\OneDrive - University of Southampton\\Documents\\Dissertation Project - Marwa Ashfaq\\Dataset\\50K_jobs_fil.xlsx\n",
      "Input file not found! Please check the path.\n",
      "Looking for: 50K jobs.xlsx\n",
      "In folder: Dataset\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "class JobDatasetFilter:\n",
    "    def __init__(self):\n",
    "        # Define relevant keywords for your research project\n",
    "        self.relevant_keywords = {\n",
    "            'operations_research': [\n",
    "                'operations research', 'operational research', 'or analyst', 'or specialist',\n",
    "                'operations analyst', 'operational analyst', 'management science',\n",
    "                'optimization', 'linear programming', 'mathematical modeling',\n",
    "                'supply chain optimization', 'logistics optimization'\n",
    "            ],\n",
    "            'data_science': [\n",
    "                'data scientist', 'data science', 'machine learning', 'artificial intelligence',\n",
    "                'ai researcher', 'ml engineer', 'data analyst', 'data engineer',\n",
    "                'statistical analyst', 'quantitative analyst', 'business intelligence',\n",
    "                'predictive analytics', 'data mining', 'big data'\n",
    "            ],\n",
    "            'analytics': [\n",
    "                'business analyst', 'systems analyst', 'research analyst', 'financial analyst',\n",
    "                'market research analyst', 'business intelligence analyst', 'reporting analyst',\n",
    "                'performance analyst', 'strategy analyst', 'planning analyst',\n",
    "                'decision analyst', 'process analyst'\n",
    "            ],\n",
    "            'quantitative_roles': [\n",
    "                'quantitative', 'quant', 'statistician', 'econometrician', 'actuary',\n",
    "                'risk analyst', 'credit analyst', 'investment analyst', 'portfolio analyst',\n",
    "                'algorithmic', 'mathematical', 'computational', 'modeling'\n",
    "            ],\n",
    "            'consulting': [\n",
    "                'management consultant', 'strategy consultant', 'business consultant',\n",
    "                'operations consultant', 'analytics consultant', 'data consultant',\n",
    "                'process improvement', 'lean six sigma', 'process optimization'\n",
    "            ],\n",
    "            'research_roles': [\n",
    "                'research scientist', 'researcher', 'research associate', 'research analyst',\n",
    "                'market researcher', 'user researcher', 'policy researcher',\n",
    "                'academic researcher', 'research engineer'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Combine all keywords into one list for easier searching\n",
    "        self.all_keywords = []\n",
    "        for category, keywords in self.relevant_keywords.items():\n",
    "            self.all_keywords.extend(keywords)\n",
    "        \n",
    "        # Industry keywords that are relevant\n",
    "        self.relevant_industries = [\n",
    "            'consulting', 'technology', 'finance', 'banking', 'insurance', 'healthcare',\n",
    "            'pharmaceuticals', 'telecommunications', 'logistics', 'supply chain',\n",
    "            'manufacturing', 'automotive', 'aerospace', 'defense', 'energy',\n",
    "            'government', 'public sector', 'research', 'academia', 'university'\n",
    "        ]\n",
    "        \n",
    "        # Keywords to exclude (irrelevant jobs) - ENHANCED VERSION\n",
    "        self.exclude_keywords = [\n",
    "            # Vehicle/Automotive\n",
    "            'vehicle technician', 'motor technician', 'automotive technician', 'lcv technician',\n",
    "            'mot tester', 'car sales', 'vehicle sales', 'automotive sales',\n",
    "            \n",
    "            # Manufacturing/Production \n",
    "            'production supervisor', 'production manager', 'production engineer', 'production team leader',\n",
    "            'production welder', 'production planner', 'manufacturing supervisor', 'manufacturing engineer',\n",
    "            'manufacturing specialist', 'assembly line', 'factory supervisor', 'plant manager',\n",
    "            \n",
    "            # CNC/Machining\n",
    "            'cnc machinist', 'cnc setter', 'cnc programmer', 'cnc operator', 'cnc miller',\n",
    "            'machinist', 'machine operator', 'machine minder', 'centreless grinder',\n",
    "            'tooling engineer', 'skilled finishing operative',\n",
    "            \n",
    "            # Legal (non-analytical)\n",
    "            'paralegal', 'solicitor', 'lawyer', 'litigation', 'conveyancer', 'legal secretary',\n",
    "            'legal administrator', 'legal executive', 'legal assistant', 'court clerk',\n",
    "            \n",
    "            # Basic Technical/Service\n",
    "            'service technician', 'field technician', 'maintenance technician', 'repair technician',\n",
    "            'installation technician', 'support technician', 'field engineer', 'service engineer',\n",
    "            'help desk', 'it support', 'desktop support', 'technical support',\n",
    "            \n",
    "            # Manual/Operational roles\n",
    "            'welder', 'grinder', 'operative', 'packer', 'picker', 'despatch', 'goods in',\n",
    "            'warehouse', 'forklift', 'driver', 'delivery', 'courier', 'cleaner',\n",
    "            'security', 'caretaker', 'porter', 'stores', 'dispatch',\n",
    "            \n",
    "            # Basic Admin/Customer Service\n",
    "            'administrator', 'admin assistant', 'office administrator', 'data entry',\n",
    "            'customer service', 'call centre', 'call center', 'customer advisor',\n",
    "            'customer service advisor', 'receptionist', 'sales assistant', 'shop assistant',\n",
    "            \n",
    "            # Recruitment (non-analytical)\n",
    "            'trainee recruitment consultant', 'recruitment consultant', 'recruitment administrator',\n",
    "            'recruitment coordinator', 'resourcer', 'talent acquisition coordinator',\n",
    "            'graduate recruitment consultant', 'recruitment advisor', 'recruitment researcher',\n",
    "            \n",
    "            # Healthcare (non-analytical)\n",
    "            'care worker', 'care assistant', 'healthcare assistant', 'support worker',\n",
    "            'nursing', 'nurse', 'physiotherapist', 'occupational therapist',\n",
    "            'medical technician', 'laboratory technician', 'clinical technician',\n",
    "            \n",
    "            # Education (basic)\n",
    "            'teacher', 'teaching assistant', 'tutor', 'instructor', 'trainer',\n",
    "            'nursery teacher', 'childcare', 'education assistant',\n",
    "            \n",
    "            # Sales (basic)\n",
    "            'sales manager', 'sales executive', 'sales advisor', 'sales representative',\n",
    "            'account executive', 'business development executive', 'telesales',\n",
    "            'telemarketing', 'cold calling'\n",
    "        ]\n",
    "        \n",
    "        # Additional strict exclusion patterns for job titles\n",
    "        self.strict_exclude_patterns = [\n",
    "            # Vehicle/Transport\n",
    "            r'\\bvehicle technician\\b', r'\\bmotor technician\\b', r'\\blcv technician\\b', r'\\bmot tester\\b',\n",
    "            \n",
    "            # Manufacturing/Production\n",
    "            r'\\bproduction\\s+(supervisor|manager|engineer|leader|welder|planner)\\b',\n",
    "            r'\\bmanufacturing\\s+(supervisor|engineer|specialist)\\b', r'\\bassembly line\\b',\n",
    "            \n",
    "            # CNC/Machining\n",
    "            r'\\bcnc\\s+(machinist|setter|programmer|operator|miller)\\b', r'\\bmachine\\s+(operator|minder)\\b',\n",
    "            \n",
    "            # Legal\n",
    "            r'\\bparalegal\\b', r'\\bsolicitor\\b', r'\\blawyer\\b', r'\\blegal\\s+(secretary|administrator|assistant)\\b',\n",
    "            \n",
    "            # Basic Technical\n",
    "            r'\\bservice technician\\b', r'\\bfield technician\\b', r'\\bmaintenance technician\\b',\n",
    "            r'\\bhelp desk\\b', r'\\bit support\\b', r'\\bdesktop support\\b',\n",
    "            \n",
    "            # Manual work\n",
    "            r'\\bwelder\\b', r'\\bgrinder\\b', r'\\boperative\\b', r'\\bpacker\\b', r'\\bpicker\\b',\n",
    "            r'\\bwarehouse\\b', r'\\bdriver\\b', r'\\bdelivery\\b', r'\\bcleaner\\b',\n",
    "            \n",
    "            # Basic admin\n",
    "            r'\\badmin\\s+(assistant|coordinator)\\b', r'\\bdata entry\\b', r'\\bcustomer service\\b',\n",
    "            r'\\bcall centre\\b', r'\\bcall center\\b', r'\\breceptionist\\b',\n",
    "            \n",
    "            # Recruitment\n",
    "            r'\\btrainee recruitment consultant\\b', r'\\brecruitment consultant\\b',\n",
    "            r'\\brecruitment\\s+(administrator|coordinator|advisor)\\b',\n",
    "            \n",
    "            # Healthcare\n",
    "            r'\\bcare\\s+(worker|assistant)\\b', r'\\bhealthcare assistant\\b', r'\\bnursing\\b',\n",
    "            \n",
    "            # Education\n",
    "            r'\\bteacher\\b', r'\\btutor\\b', r'\\bteaching assistant\\b',\n",
    "            \n",
    "            # Basic sales\n",
    "            r'\\bsales\\s+(manager|executive|advisor|representative)\\b', r'\\btelesales\\b', r'\\btelemarketing\\b'\n",
    "        ]\n",
    "\n",
    "    def load_dataset(self, file_path):\n",
    "        \"\"\"Load the dataset from various file formats\"\"\"\n",
    "        try:\n",
    "            file_extension = os.path.splitext(file_path)[1].lower()\n",
    "            \n",
    "            if file_extension == '.csv':\n",
    "                # Try different encodings and separators\n",
    "                encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1', 'utf-16', 'utf-8-sig']\n",
    "                separators = [',', ';', '\\t']\n",
    "                \n",
    "                for encoding in encodings:\n",
    "                    for sep in separators:\n",
    "                        try:\n",
    "                            print(f\"Trying encoding: {encoding} with separator: '{sep}'\")\n",
    "                            df = pd.read_csv(file_path, encoding=encoding, sep=sep, on_bad_lines='skip')\n",
    "                            \n",
    "                            # Check if we got a reasonable number of columns\n",
    "                            if len(df.columns) >= 5:  # Expecting at least 5 columns based on your description\n",
    "                                print(f\"Successfully loaded CSV with {encoding} encoding and '{sep}' separator\")\n",
    "                                print(f\"Columns found: {list(df.columns)}\")\n",
    "                                return df\n",
    "                        except Exception as e:\n",
    "                            print(f\"Failed with {encoding}/{sep}: {str(e)[:50]}...\")\n",
    "                            continue\n",
    "                \n",
    "                # If all encodings fail, try with error handling\n",
    "                print(\"Trying with error handling...\")\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path, encoding='utf-8', errors='ignore', on_bad_lines='skip')\n",
    "                    print(\"Loaded with error handling (some characters may be missing)\")\n",
    "                    return df\n",
    "                except:\n",
    "                    try:\n",
    "                        df = pd.read_csv(file_path, encoding='latin-1', errors='ignore', on_bad_lines='skip')\n",
    "                        print(\"Loaded with latin-1 and error handling\")\n",
    "                        return df\n",
    "                    except Exception as e:\n",
    "                        raise Exception(f\"Could not read CSV with any method: {e}\")\n",
    "                    \n",
    "            elif file_extension in ['.xlsx', '.xls']:\n",
    "                df = pd.read_excel(file_path)\n",
    "                \n",
    "            elif file_extension == '.json':\n",
    "                df = pd.read_json(file_path)\n",
    "                \n",
    "            else:\n",
    "                raise Exception(f\"Unsupported file format: {file_extension}\")\n",
    "            \n",
    "            print(f\"Dataset loaded successfully!\")\n",
    "            print(f\"Shape: {df.shape}\")\n",
    "            print(f\"Columns: {list(df.columns)}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading dataset: {e}\")\n",
    "            print(\"\\nTroubleshooting suggestions:\")\n",
    "            print(\"1. Check if the file is not corrupted\")\n",
    "            print(\"2. Try opening the file in Excel/text editor to check format\")\n",
    "            print(\"3. Make sure the file is not being used by another program\")\n",
    "            print(\"4. Try converting the file to UTF-8 encoding in a text editor\")\n",
    "            return None\n",
    "\n",
    "    def analyze_dataset_structure(self, df):\n",
    "        \"\"\"Analyze the structure of the dataset\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DATASET ANALYSIS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(f\"Total rows: {len(df):,}\")\n",
    "        print(f\"Total columns: {len(df.columns)}\")\n",
    "        \n",
    "        print(\"\\nColumn Information:\")\n",
    "        for i, col in enumerate(df.columns):\n",
    "            non_null_count = df[col].count()\n",
    "            sample_values = df[col].dropna().head(3).tolist()\n",
    "            print(f\"{i+1:2}. {col}\")\n",
    "            print(f\"    Non-null: {non_null_count:,} ({non_null_count/len(df)*100:.1f}%)\")\n",
    "            print(f\"    Sample: {sample_values}\")\n",
    "        \n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def identify_text_columns(self, df):\n",
    "        \"\"\"Identify which columns contain job titles and descriptions\"\"\"\n",
    "        text_columns = {\n",
    "            'title': None,\n",
    "            'description': None,\n",
    "            'company': None,\n",
    "            'location': None,\n",
    "            'requirements': None,\n",
    "            'category': None\n",
    "        }\n",
    "        \n",
    "        # Specific mapping for your dataset\n",
    "        column_mapping = {\n",
    "            'job_title': 'title',\n",
    "            'job_description': 'description', \n",
    "            'company_name': 'company',\n",
    "            'city': 'location',\n",
    "            'job_requirements': 'requirements',\n",
    "            'category': 'category'\n",
    "        }\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if col in column_mapping:\n",
    "                text_columns[column_mapping[col]] = col\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"IDENTIFIED COLUMNS\")\n",
    "        print(\"=\"*60)\n",
    "        for key, value in text_columns.items():\n",
    "            if value:\n",
    "                print(f\"{key.title()}: {value}\")\n",
    "        \n",
    "        return text_columns\n",
    "\n",
    "    def manual_column_selection(self, df):\n",
    "        \"\"\"Allow manual selection of columns if auto-detection fails\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"MANUAL COLUMN SELECTION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        columns = list(df.columns)\n",
    "        for i, col in enumerate(columns):\n",
    "            print(f\"{i+1:2}. {col}\")\n",
    "        \n",
    "        text_columns = {}\n",
    "        \n",
    "        # Get job title column\n",
    "        while True:\n",
    "            try:\n",
    "                choice = input(\"\\nEnter number for JOB TITLE column (or press Enter to skip): \").strip()\n",
    "                if choice == \"\":\n",
    "                    text_columns['title'] = None\n",
    "                    break\n",
    "                idx = int(choice) - 1\n",
    "                if 0 <= idx < len(columns):\n",
    "                    text_columns['title'] = columns[idx]\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Invalid number. Please try again.\")\n",
    "            except ValueError:\n",
    "                print(\"Please enter a valid number.\")\n",
    "        \n",
    "        # Get job description column\n",
    "        while True:\n",
    "            try:\n",
    "                choice = input(\"Enter number for JOB DESCRIPTION column (or press Enter to skip): \").strip()\n",
    "                if choice == \"\":\n",
    "                    text_columns['description'] = None\n",
    "                    break\n",
    "                idx = int(choice) - 1\n",
    "                if 0 <= idx < len(columns):\n",
    "                    text_columns['description'] = columns[idx]\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Invalid number. Please try again.\")\n",
    "            except ValueError:\n",
    "                print(\"Please enter a valid number.\")\n",
    "        \n",
    "        # Get company column\n",
    "        while True:\n",
    "            try:\n",
    "                choice = input(\"Enter number for COMPANY column (or press Enter to skip): \").strip()\n",
    "                if choice == \"\":\n",
    "                    text_columns['company'] = None\n",
    "                    break\n",
    "                idx = int(choice) - 1\n",
    "                if 0 <= idx < len(columns):\n",
    "                    text_columns['company'] = columns[idx]\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Invalid number. Please try again.\")\n",
    "            except ValueError:\n",
    "                print(\"Please enter a valid number.\")\n",
    "        \n",
    "        # Get location column\n",
    "        while True:\n",
    "            try:\n",
    "                choice = input(\"Enter number for LOCATION column (or press Enter to skip): \").strip()\n",
    "                if choice == \"\":\n",
    "                    text_columns['location'] = None\n",
    "                    break\n",
    "                idx = int(choice) - 1\n",
    "                if 0 <= idx < len(columns):\n",
    "                    text_columns['location'] = columns[idx]\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Invalid number. Please try again.\")\n",
    "            except ValueError:\n",
    "                print(\"Please enter a valid number.\")\n",
    "        \n",
    "        return text_columns\n",
    "\n",
    "    def check_keyword_match(self, text, keywords, exclude_keywords=None):\n",
    "        \"\"\"Check if text contains any of the keywords with enhanced filtering\"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return False, []\n",
    "        \n",
    "        text_lower = str(text).lower()\n",
    "        \n",
    "        # Priority inclusion list - these should ALWAYS be included even if they match exclude patterns\n",
    "        priority_include = [\n",
    "            'data scientist', 'data analyst', 'business analyst', 'research analyst',\n",
    "            'quantitative analyst', 'financial analyst', 'credit analyst', 'risk analyst',\n",
    "            'operations analyst', 'business intelligence', 'machine learning', 'statistician',\n",
    "            'econometrician', 'actuarial analyst', 'modelling', 'optimization',\n",
    "            'operations research', 'management science', 'decision science'\n",
    "        ]\n",
    "        \n",
    "        # Check for priority inclusion first\n",
    "        for priority_term in priority_include:\n",
    "            if priority_term in text_lower:\n",
    "                return True, [f\"PRIORITY: {priority_term}\"]\n",
    "        \n",
    "        # Check for strict exclude patterns (using regex for exact matches)\n",
    "        for pattern in self.strict_exclude_patterns:\n",
    "            if re.search(pattern, text_lower):\n",
    "                matched_word = re.search(pattern, text_lower).group()\n",
    "                return False, [f\"EXCLUDED: {matched_word}\"]\n",
    "        \n",
    "        # Check for exclude keywords\n",
    "        if exclude_keywords:\n",
    "            for exclude_word in exclude_keywords:\n",
    "                if exclude_word.lower() in text_lower:\n",
    "                    return False, [f\"EXCLUDED: {exclude_word}\"]\n",
    "        \n",
    "        # Check for relevant keywords\n",
    "        found_keywords = []\n",
    "        for keyword in keywords:\n",
    "            if keyword.lower() in text_lower:\n",
    "                found_keywords.append(keyword)\n",
    "        \n",
    "        return len(found_keywords) > 0, found_keywords\n",
    "\n",
    "    def filter_relevant_jobs(self, df, text_columns, strict_mode=False):\n",
    "        \"\"\"Filter the dataset for relevant jobs\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"FILTERING JOBS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        relevant_jobs = []\n",
    "        total_jobs = len(df)\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            if idx % 5000 == 0:\n",
    "                print(f\"Processed {idx:,} of {total_jobs:,} jobs...\")\n",
    "            \n",
    "            # Combine title, description, requirements, and category for searching\n",
    "            search_text = \"\"\n",
    "            found_keywords = []\n",
    "            \n",
    "            if text_columns['title'] and not pd.isna(row[text_columns['title']]):\n",
    "                search_text += str(row[text_columns['title']]) + \" \"\n",
    "            \n",
    "            if text_columns['description'] and not pd.isna(row[text_columns['description']]):\n",
    "                search_text += str(row[text_columns['description']]) + \" \"\n",
    "            \n",
    "            if text_columns['requirements'] and not pd.isna(row[text_columns['requirements']]):\n",
    "                search_text += str(row[text_columns['requirements']]) + \" \"\n",
    "                \n",
    "            if text_columns['category'] and not pd.isna(row[text_columns['category']]):\n",
    "                search_text += str(row[text_columns['category']]) + \" \"\n",
    "            \n",
    "            if text_columns['company'] and not pd.isna(row[text_columns['company']]):\n",
    "                search_text += str(row[text_columns['company']]) + \" \"\n",
    "            \n",
    "            # Check for relevance\n",
    "            is_relevant, keywords_found = self.check_keyword_match(\n",
    "                search_text, self.all_keywords, self.exclude_keywords\n",
    "            )\n",
    "            \n",
    "            if is_relevant:\n",
    "                # Add additional information to the row\n",
    "                row_dict = row.to_dict()\n",
    "                row_dict['keywords_found'] = '; '.join(keywords_found)\n",
    "                row_dict['filter_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                relevant_jobs.append(row_dict)\n",
    "        \n",
    "        print(f\"\\nFiltering complete!\")\n",
    "        print(f\"Original jobs: {total_jobs:,}\")\n",
    "        print(f\"Relevant jobs found: {len(relevant_jobs):,}\")\n",
    "        print(f\"Percentage relevant: {len(relevant_jobs)/total_jobs*100:.2f}%\")\n",
    "        \n",
    "        return pd.DataFrame(relevant_jobs)\n",
    "\n",
    "    def save_filtered_data(self, filtered_df, output_path):\n",
    "        \"\"\"Save the filtered dataset\"\"\"\n",
    "        try:\n",
    "            # Ensure output directory exists\n",
    "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "            \n",
    "            # Save to Excel\n",
    "            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "                filtered_df.to_excel(writer, sheet_name='Relevant_Jobs', index=False)\n",
    "            \n",
    "            print(f\"\\nFiltered data saved to: {output_path}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving filtered data: {e}\")\n",
    "            return False\n",
    "\n",
    "    def show_sample_results(self, filtered_df, text_columns, n_samples=10):\n",
    "        \"\"\"Show sample results from filtering\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SAMPLE FILTERED RESULTS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if len(filtered_df) == 0:\n",
    "            print(\"No relevant jobs found!\")\n",
    "            return\n",
    "        \n",
    "        sample_df = filtered_df.head(n_samples)\n",
    "        \n",
    "        for idx, row in sample_df.iterrows():\n",
    "            print(f\"\\nJob {idx + 1}:\")\n",
    "            print(\"-\" * 30)\n",
    "            if text_columns['title']:\n",
    "                print(f\"Title: {row[text_columns['title']]}\")\n",
    "            if text_columns['company']:\n",
    "                print(f\"Company: {row[text_columns['company']]}\")\n",
    "            if text_columns['location']:\n",
    "                print(f\"Location: {row[text_columns['location']]}\")\n",
    "            if text_columns['category']:\n",
    "                print(f\"Category: {row[text_columns['category']]}\")\n",
    "            if 'keywords_found' in row:\n",
    "                print(f\"Keywords Found: {row['keywords_found']}\")\n",
    "        \n",
    "        # Ask user if they want to add more exclusions\n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"QUALITY CHECK\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"Review the sample results above. Do you see any irrelevant jobs?\")\n",
    "        print(\"If yes, you can add custom exclusions to improve the filtering.\")\n",
    "        \n",
    "        add_exclusions = input(\"\\nDo you want to add custom exclusion keywords? (y/n): \").strip().lower()\n",
    "        \n",
    "        if add_exclusions in ['y', 'yes']:\n",
    "            print(\"\\nEnter keywords to exclude (separated by commas):\")\n",
    "            print(\"Example: sales rep, customer service, admin clerk\")\n",
    "            custom_exclusions = input(\"Keywords to exclude: \").strip()\n",
    "            \n",
    "            if custom_exclusions:\n",
    "                new_exclusions = [keyword.strip() for keyword in custom_exclusions.split(',')]\n",
    "                return new_exclusions\n",
    "        \n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the job filtering process\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"UK JOBS DATASET FILTER - RELEVANT JOBS EXTRACTOR\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"This tool filters large job datasets to find relevant positions\")\n",
    "    print(\"for Operations Research, Data Science, and Analytics roles.\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Pre-configured paths for your Excel dataset\n",
    "    input_path = r\"C:\\Users\\HP\\OneDrive - University of Southampton\\Documents\\Dissertation Project - Marwa Ashfaq\\Dataset\\50K jobs.xlsx\"\n",
    "    output_path = r\"C:\\Users\\HP\\OneDrive - University of Southampton\\Documents\\Dissertation Project - Marwa Ashfaq\\Dataset\\50K_jobs_filtered.xlsx\"\n",
    "    \n",
    "    print(f\"Input file: {input_path}\")\n",
    "    print(f\"Output file: {output_path}\")\n",
    "    \n",
    "    # Initialize filter\n",
    "    filter_tool = JobDatasetFilter()\n",
    "    \n",
    "    # Check if input file exists\n",
    "    if not os.path.exists(input_path):\n",
    "        print(\"Input file not found! Please check the path.\")\n",
    "        print(\"Looking for: 50K jobs.xlsx\")\n",
    "        print(\"In folder: Dataset\")\n",
    "        return\n",
    "    \n",
    "    # Load dataset\n",
    "    print(\"\\nLoading Excel dataset...\")\n",
    "    print(\"This may take a moment for large files...\")\n",
    "    df = filter_tool.load_dataset(input_path)\n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    # Analyze dataset structure\n",
    "    filter_tool.analyze_dataset_structure(df)\n",
    "    \n",
    "    # Identify text columns (pre-configured for your dataset)\n",
    "    text_columns = filter_tool.identify_text_columns(df)\n",
    "    \n",
    "    # Show what will be searched\n",
    "    print(\"\\nColumns that will be searched for relevant keywords:\")\n",
    "    for key, col in text_columns.items():\n",
    "        if col:\n",
    "            print(f\"  {key.title()}: {col}\")\n",
    "    \n",
    "    # Filter relevant jobs\n",
    "    print(f\"\\nStarting to filter {len(df):,} jobs...\")\n",
    "    print(\"This may take a few minutes for large datasets...\")\n",
    "    \n",
    "    filtered_df = filter_tool.filter_relevant_jobs(df, text_columns)\n",
    "    \n",
    "    # Show sample results and get custom exclusions\n",
    "    custom_exclusions = filter_tool.show_sample_results(filtered_df, text_columns)\n",
    "    \n",
    "    # If user wants to add custom exclusions, re-filter\n",
    "    if custom_exclusions:\n",
    "        print(f\"\\nRe-filtering with custom exclusions: {custom_exclusions}\")\n",
    "        filter_tool.exclude_keywords.extend(custom_exclusions)\n",
    "        filtered_df = filter_tool.filter_relevant_jobs(df, text_columns)\n",
    "        print(\"\\nRe-filtering complete!\")\n",
    "        \n",
    "        # Show new sample\n",
    "        filter_tool.show_sample_results(filtered_df, text_columns, n_samples=5)\n",
    "    \n",
    "    # Save filtered data\n",
    "    if len(filtered_df) > 0:\n",
    "        success = filter_tool.save_filtered_data(filtered_df, output_path)\n",
    "        \n",
    "        if success:\n",
    "            print(\"\\n\" + \"=\"*70)\n",
    "            print(\"FILTERING COMPLETED SUCCESSFULLY!\")\n",
    "            print(\"=\"*70)\n",
    "            print(f\"Original dataset: {len(df):,} jobs\")\n",
    "            print(f\"Filtered dataset: {len(filtered_df):,} relevant jobs\")\n",
    "            print(f\"Reduction: {(1 - len(filtered_df)/len(df))*100:.1f}%\")\n",
    "            print(f\"Saved to: {output_path}\")\n",
    "            \n",
    "            # Show category breakdown if available\n",
    "            if 'category' in filtered_df.columns:\n",
    "                print(f\"\\nTop job categories in filtered results:\")\n",
    "                category_counts = filtered_df['category'].value_counts().head(10)\n",
    "                for category, count in category_counts.items():\n",
    "                    print(f\"  {category}: {count}\")\n",
    "                    \n",
    "        else:\n",
    "            print(\"Failed to save filtered data.\")\n",
    "    else:\n",
    "        print(\"\\nNo relevant jobs found with current criteria.\")\n",
    "        print(\"You may need to adjust the keywords or filtering criteria.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d6909-c56b-4fbb-bbd1-9d5884dbdc63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
