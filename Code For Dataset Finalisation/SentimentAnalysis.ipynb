{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f2f4c2-fc59-405a-ab9a-ab8991204fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: nltk in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2025.6.15)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob vaderSentiment nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8184e3ed-f64e-4d79-b4a2-64edbadf8c93",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2621292756.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    python -m textblob.download_corpora\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62ba9fae-5b0a-442c-8829-28aeae6598fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: vaderSentiment in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user textblob vaderSentiment nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cb3540b-ac4e-4d02-98b6-e1bb78db0b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All packages installed successfully!\n",
      "âœ… Packages working correctly!\n"
     ]
    }
   ],
   "source": [
    "# test_packages.py\n",
    "try:\n",
    "    from textblob import TextBlob\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    import nltk\n",
    "    print(\"âœ… All packages installed successfully!\")\n",
    "    \n",
    "    # Test basic functionality\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    blob = TextBlob(\"This is a test\")\n",
    "    print(\"âœ… Packages working correctly!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77dce996-afc5-4a37-ac78-a94cb769e4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking required packages...\n",
      "âœ… All required packages available\n",
      "======================================================================\n",
      "OR JOBS SENTIMENT ANALYSIS - COMPLEMENTING LEXICON SCORES\n",
      "======================================================================\n",
      "This will add comprehensive sentiment analysis to your existing\n",
      "lexicon-scored dataset for validation and deeper insights.\n",
      "======================================================================\n",
      "ðŸ“ Reading existing dataset...\n",
      "âœ… Loaded 1,233 jobs with 22 columns\n",
      "\n",
      "======================================================================\n",
      "ADDING SENTIMENT ANALYSIS TO OR JOBS DATASET\n",
      "======================================================================\n",
      "ðŸ“ Analyzing sentiment from column: job_description\n",
      "ðŸ“Š Processing 1,233 job descriptions...\n",
      "âœ… Sentiment analysis complete!\n",
      "\n",
      "======================================================================\n",
      "VALIDATION ANALYSIS: SENTIMENT vs LEXICON SCORES\n",
      "======================================================================\n",
      "ðŸ” Cross-validating sentiment and lexicon analyses...\n",
      "ðŸ“ˆ Correlation Analysis:\n",
      "   Sentiment vs Gender Ratio: 0.018\n",
      "   OR Sentiment vs Lexicon Gender: 0.102\n",
      "   Gender Sentiment vs Lexicon: 0.261\n",
      "\n",
      "ðŸŽ¯ Agreement Analysis:\n",
      "   Overall Agreement: 22.4%\n",
      "\n",
      "âš ï¸  Conflicting Cases:\n",
      "   Positive sentiment + Masculine coding: 99\n",
      "   Negative sentiment + Feminine coding: 0\n",
      "\n",
      "======================================================================\n",
      "SENTIMENT ANALYSIS SUMMARY\n",
      "======================================================================\n",
      "ðŸ“Š Sentiment Classification:\n",
      "   Positive: 1,227 (99.5%)\n",
      "   Negative: 4 (0.3%)\n",
      "   Neutral: 2 (0.2%)\n",
      "\n",
      "ðŸ“ˆ Average Sentiment Scores:\n",
      "   sentiment_polarity: 0.203\n",
      "   vader_compound: 0.969\n",
      "   or_sentiment_ratio: 1.195\n",
      "\n",
      "ðŸŽ¯ OR-Specific Sentiment:\n",
      "   Average positive score: 1.75%\n",
      "   Average negative score: 0.55%\n",
      "   Average sentiment ratio: 1.20\n",
      "\n",
      "âš–ï¸  Gender Sentiment Patterns:\n",
      "   Average gender sentiment ratio: 36.95\n",
      "   Jobs with masculine sentiment patterns: 908\n",
      "   Jobs with feminine sentiment patterns: 156\n",
      "\n",
      "ðŸ’¾ Saving updated dataset with sentiment analysis...\n",
      "âœ… Updated dataset saved to: C:\\Users\\HP\\OneDrive - University of Southampton\\Documents\\Dissertation Project - Marwa Ashfaq\\Dataset\\Final Dataset.xlsx\n",
      "ðŸ“Š Total columns now: 38\n",
      "\n",
      "ðŸ“‹ New Sentiment Columns Added:\n",
      "   sentiment_polarity\n",
      "   sentiment_subjectivity\n",
      "   vader_compound\n",
      "   vader_positive\n",
      "   vader_neutral\n",
      "   vader_negative\n",
      "   or_sentiment_ratio\n",
      "   masculine_sentiment_count\n",
      "   feminine_sentiment_count\n",
      "   gender_sentiment_ratio\n",
      "\n",
      "ðŸŽ‰ SENTIMENT ANALYSIS COMPLETE!\n",
      "Your dataset now has both lexicon and sentiment analysis for\n",
      "comprehensive validation and deeper insights into gendered language!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# For more advanced sentiment analysis\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.sentiment import SentimentIntensityAnalyzer as NLTKSentimentAnalyzer\n",
    "    from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    \n",
    "    # Download required NLTK data\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('vader_lexicon', quiet=True)\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "    nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "    \n",
    "    NLTK_AVAILABLE = True\n",
    "except ImportError:\n",
    "    NLTK_AVAILABLE = False\n",
    "    print(\"âš ï¸  NLTK not available. Using basic sentiment analysis only.\")\n",
    "\n",
    "class ORJobSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize sentiment analyzer with multiple approaches\"\"\"\n",
    "        \n",
    "        # Initialize VADER sentiment analyzer\n",
    "        self.vader_analyzer = SentimentIntensityAnalyzer()\n",
    "        \n",
    "        # Initialize NLTK components if available\n",
    "        if NLTK_AVAILABLE:\n",
    "            self.nltk_analyzer = NLTKSentimentAnalyzer()\n",
    "            self.lemmatizer = WordNetLemmatizer()\n",
    "            self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        # OR-specific positive sentiment words (indicating confidence, competence)\n",
    "        self.or_positive_words = [\n",
    "            'excellent', 'outstanding', 'exceptional', 'innovative', 'leading',\n",
    "            'cutting-edge', 'state-of-the-art', 'world-class', 'premier', 'top-tier',\n",
    "            'advanced', 'sophisticated', 'dynamic', 'progressive', 'forward-thinking',\n",
    "            'strategic', 'impactful', 'successful', 'effective', 'efficient',\n",
    "            'robust', 'comprehensive', 'extensive', 'diverse', 'inclusive',\n",
    "            'collaborative', 'supportive', 'rewarding', 'exciting', 'challenging',\n",
    "            'opportunity', 'growth', 'development', 'career', 'advancement'\n",
    "        ]\n",
    "        \n",
    "        # OR-specific negative sentiment words (indicating barriers, difficulty)\n",
    "        self.or_negative_words = [\n",
    "            'demanding', 'pressure', 'stress', 'intense', 'rigid', 'strict',\n",
    "            'challenging', 'difficult', 'complex', 'overwhelming', 'competitive',\n",
    "            'aggressive', 'fast-paced', 'high-pressure', 'demanding',\n",
    "            'must', 'required', 'essential', 'critical', 'mandatory'\n",
    "        ]\n",
    "        \n",
    "        # Gender-related sentiment patterns\n",
    "        self.masculine_sentiment_patterns = [\n",
    "            r'dominate\\w*', r'lead\\w*', r'control\\w*', r'manage\\w*', r'direct\\w*',\n",
    "            r'achieve\\w*', r'win\\w*', r'excel\\w*', r'compete\\w*', r'drive\\w*'\n",
    "        ]\n",
    "        \n",
    "        self.feminine_sentiment_patterns = [\n",
    "            r'support\\w*', r'help\\w*', r'assist\\w*', r'collaborate\\w*', r'cooperate\\w*',\n",
    "            r'nurture\\w*', r'care\\w*', r'understand\\w*', r'empathize\\w*', r'connect\\w*'\n",
    "        ]\n",
    "\n",
    "    def clean_text_for_sentiment(self, text):\n",
    "        \"\"\"Clean text specifically for sentiment analysis\"\"\"\n",
    "        if pd.isna(text) or text is None:\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to string\n",
    "        text = str(text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        # Remove special characters but keep sentence structure\n",
    "        text = re.sub(r'[^\\w\\s\\.\\!\\?\\;\\:]', ' ', text)\n",
    "        \n",
    "        # Remove multiple spaces\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        return text.strip()\n",
    "\n",
    "    def calculate_textblob_sentiment(self, text):\n",
    "        \"\"\"Calculate sentiment using TextBlob\"\"\"\n",
    "        try:\n",
    "            blob = TextBlob(text)\n",
    "            polarity = blob.sentiment.polarity  # -1 (negative) to 1 (positive)\n",
    "            subjectivity = blob.sentiment.subjectivity  # 0 (objective) to 1 (subjective)\n",
    "            \n",
    "            return {\n",
    "                'polarity': round(polarity, 3),\n",
    "                'subjectivity': round(subjectivity, 3)\n",
    "            }\n",
    "        except:\n",
    "            return {'polarity': 0.0, 'subjectivity': 0.0}\n",
    "\n",
    "    def calculate_vader_sentiment(self, text):\n",
    "        \"\"\"Calculate sentiment using VADER\"\"\"\n",
    "        try:\n",
    "            scores = self.vader_analyzer.polarity_scores(text)\n",
    "            return {\n",
    "                'compound': round(scores['compound'], 3),\n",
    "                'positive': round(scores['pos'], 3),\n",
    "                'neutral': round(scores['neu'], 3),\n",
    "                'negative': round(scores['neg'], 3)\n",
    "            }\n",
    "        except:\n",
    "            return {'compound': 0.0, 'positive': 0.0, 'neutral': 0.0, 'negative': 0.0}\n",
    "\n",
    "    def calculate_or_specific_sentiment(self, text):\n",
    "        \"\"\"Calculate OR-specific sentiment scores\"\"\"\n",
    "        if not text:\n",
    "            return {'or_positive_score': 0.0, 'or_negative_score': 0.0, 'or_sentiment_ratio': 0.0}\n",
    "        \n",
    "        text_lower = text.lower()\n",
    "        words = re.findall(r'\\b[a-z]+\\b', text_lower)\n",
    "        total_words = len(words)\n",
    "        \n",
    "        if total_words == 0:\n",
    "            return {'or_positive_score': 0.0, 'or_negative_score': 0.0, 'or_sentiment_ratio': 0.0}\n",
    "        \n",
    "        # Count OR-specific sentiment words\n",
    "        positive_count = sum(1 for word in words if word in self.or_positive_words)\n",
    "        negative_count = sum(1 for word in words if word in self.or_negative_words)\n",
    "        \n",
    "        positive_score = round((positive_count / total_words) * 100, 2)\n",
    "        negative_score = round((negative_count / total_words) * 100, 2)\n",
    "        sentiment_ratio = round(positive_score - negative_score, 2)\n",
    "        \n",
    "        return {\n",
    "            'or_positive_score': positive_score,\n",
    "            'or_negative_score': negative_score,\n",
    "            'or_sentiment_ratio': sentiment_ratio\n",
    "        }\n",
    "\n",
    "    def calculate_gender_sentiment_patterns(self, text):\n",
    "        \"\"\"Analyze sentiment patterns related to gender\"\"\"\n",
    "        if not text:\n",
    "            return {\n",
    "                'masculine_sentiment_count': 0,\n",
    "                'feminine_sentiment_count': 0,\n",
    "                'gender_sentiment_ratio': 0.0\n",
    "            }\n",
    "        \n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Count gender-related sentiment patterns\n",
    "        masculine_count = sum(len(re.findall(pattern, text_lower)) for pattern in self.masculine_sentiment_patterns)\n",
    "        feminine_count = sum(len(re.findall(pattern, text_lower)) for pattern in self.feminine_sentiment_patterns)\n",
    "        \n",
    "        # Calculate ratio\n",
    "        total_gender_sentiment = masculine_count + feminine_count\n",
    "        if total_gender_sentiment > 0:\n",
    "            ratio = round((masculine_count - feminine_count) / total_gender_sentiment * 100, 2)\n",
    "        else:\n",
    "            ratio = 0.0\n",
    "        \n",
    "        return {\n",
    "            'masculine_sentiment_count': masculine_count,\n",
    "            'feminine_sentiment_count': feminine_count,\n",
    "            'gender_sentiment_ratio': ratio\n",
    "        }\n",
    "\n",
    "    def calculate_comprehensive_sentiment(self, text):\n",
    "        \"\"\"Calculate all sentiment metrics for a text\"\"\"\n",
    "        \n",
    "        if not text:\n",
    "            return {\n",
    "                # TextBlob metrics\n",
    "                'sentiment_polarity': 0.0,\n",
    "                'sentiment_subjectivity': 0.0,\n",
    "                \n",
    "                # VADER metrics\n",
    "                'vader_compound': 0.0,\n",
    "                'vader_positive': 0.0,\n",
    "                'vader_neutral': 0.0,\n",
    "                'vader_negative': 0.0,\n",
    "                \n",
    "                # OR-specific metrics\n",
    "                'or_positive_score': 0.0,\n",
    "                'or_negative_score': 0.0,\n",
    "                'or_sentiment_ratio': 0.0,\n",
    "                \n",
    "                # Gender sentiment patterns\n",
    "                'masculine_sentiment_count': 0,\n",
    "                'feminine_sentiment_count': 0,\n",
    "                'gender_sentiment_ratio': 0.0,\n",
    "                \n",
    "                # Overall classification\n",
    "                'sentiment_classification': 'Neutral',\n",
    "                'sentiment_confidence': 0.0\n",
    "            }\n",
    "        \n",
    "        # Clean text\n",
    "        clean_text = self.clean_text_for_sentiment(text)\n",
    "        \n",
    "        # Calculate different sentiment measures\n",
    "        textblob_results = self.calculate_textblob_sentiment(clean_text)\n",
    "        vader_results = self.calculate_vader_sentiment(clean_text)\n",
    "        or_results = self.calculate_or_specific_sentiment(clean_text)\n",
    "        gender_results = self.calculate_gender_sentiment_patterns(clean_text)\n",
    "        \n",
    "        # Determine overall sentiment classification\n",
    "        # Use VADER compound score as primary classifier\n",
    "        compound_score = vader_results['compound']\n",
    "        \n",
    "        if compound_score >= 0.05:\n",
    "            classification = 'Positive'\n",
    "            confidence = abs(compound_score)\n",
    "        elif compound_score <= -0.05:\n",
    "            classification = 'Negative'\n",
    "            confidence = abs(compound_score)\n",
    "        else:\n",
    "            classification = 'Neutral'\n",
    "            confidence = 1 - abs(compound_score)\n",
    "        \n",
    "        # Combine all results\n",
    "        return {\n",
    "            # TextBlob metrics\n",
    "            'sentiment_polarity': textblob_results['polarity'],\n",
    "            'sentiment_subjectivity': textblob_results['subjectivity'],\n",
    "            \n",
    "            # VADER metrics\n",
    "            'vader_compound': vader_results['compound'],\n",
    "            'vader_positive': vader_results['positive'],\n",
    "            'vader_neutral': vader_results['neutral'],\n",
    "            'vader_negative': vader_results['negative'],\n",
    "            \n",
    "            # OR-specific metrics\n",
    "            'or_positive_score': or_results['or_positive_score'],\n",
    "            'or_negative_score': or_results['or_negative_score'],\n",
    "            'or_sentiment_ratio': or_results['or_sentiment_ratio'],\n",
    "            \n",
    "            # Gender sentiment patterns\n",
    "            'masculine_sentiment_count': gender_results['masculine_sentiment_count'],\n",
    "            'feminine_sentiment_count': gender_results['feminine_sentiment_count'],\n",
    "            'gender_sentiment_ratio': gender_results['gender_sentiment_ratio'],\n",
    "            \n",
    "            # Overall classification\n",
    "            'sentiment_classification': classification,\n",
    "            'sentiment_confidence': round(confidence, 3)\n",
    "        }\n",
    "\n",
    "    def add_sentiment_analysis_to_dataset(self, df):\n",
    "        \"\"\"Add comprehensive sentiment analysis to the existing dataset\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ADDING SENTIMENT ANALYSIS TO OR JOBS DATASET\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Identify text column for analysis\n",
    "        text_column = None\n",
    "        possible_text_columns = ['job_description', 'description', 'combined_text_for_analysis', 'job_title']\n",
    "        \n",
    "        for col in possible_text_columns:\n",
    "            if col in df.columns and df[col].notna().sum() > 0:\n",
    "                text_column = col\n",
    "                break\n",
    "        \n",
    "        if text_column is None:\n",
    "            raise ValueError(\"No suitable text column found for sentiment analysis\")\n",
    "        \n",
    "        print(f\"ðŸ“ Analyzing sentiment from column: {text_column}\")\n",
    "        print(f\"ðŸ“Š Processing {len(df):,} job descriptions...\")\n",
    "        \n",
    "        # Apply sentiment analysis\n",
    "        sentiment_results = df[text_column].fillna('').apply(self.calculate_comprehensive_sentiment)\n",
    "        \n",
    "        # Extract results into separate columns\n",
    "        sentiment_metrics = [\n",
    "            'sentiment_polarity', 'sentiment_subjectivity', 'vader_compound',\n",
    "            'vader_positive', 'vader_neutral', 'vader_negative',\n",
    "            'or_positive_score', 'or_negative_score', 'or_sentiment_ratio',\n",
    "            'masculine_sentiment_count', 'feminine_sentiment_count', \n",
    "            'gender_sentiment_ratio', 'sentiment_classification', 'sentiment_confidence'\n",
    "        ]\n",
    "        \n",
    "        for metric in sentiment_metrics:\n",
    "            df[f'{metric}'] = [result[metric] for result in sentiment_results]\n",
    "        \n",
    "        # Add analysis metadata\n",
    "        df['sentiment_analysis_date'] = datetime.now().strftime('%Y-%m-%d')\n",
    "        df['sentiment_text_column'] = text_column\n",
    "        \n",
    "        print(\"âœ… Sentiment analysis complete!\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_validation_analysis(self, df):\n",
    "        \"\"\"Create analysis comparing sentiment and lexicon scores for validation\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"VALIDATION ANALYSIS: SENTIMENT vs LEXICON SCORES\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        validation_results = {}\n",
    "        \n",
    "        # Check if lexicon columns exist\n",
    "        lexicon_cols = ['lexicon_gender_classification', 'lexicon_gender_ratio', \n",
    "                       'lexicon_masculine_score', 'lexicon_feminine_score']\n",
    "        \n",
    "        has_lexicon = all(col in df.columns for col in lexicon_cols)\n",
    "        \n",
    "        if has_lexicon:\n",
    "            print(\"ðŸ” Cross-validating sentiment and lexicon analyses...\")\n",
    "            \n",
    "            # 1. Correlation between sentiment and gender scores\n",
    "            correlations = {}\n",
    "            \n",
    "            # Vader compound vs gender ratio\n",
    "            if 'vader_compound' in df.columns and 'lexicon_gender_ratio' in df.columns:\n",
    "                corr = df['vader_compound'].corr(df['lexicon_gender_ratio'])\n",
    "                correlations['Sentiment vs Gender Ratio'] = round(corr, 3)\n",
    "            \n",
    "            # OR sentiment ratio vs lexicon gender ratio\n",
    "            if 'or_sentiment_ratio' in df.columns and 'lexicon_gender_ratio' in df.columns:\n",
    "                corr = df['or_sentiment_ratio'].corr(df['lexicon_gender_ratio'])\n",
    "                correlations['OR Sentiment vs Lexicon Gender'] = round(corr, 3)\n",
    "            \n",
    "            # Gender sentiment vs lexicon scores\n",
    "            if 'gender_sentiment_ratio' in df.columns and 'lexicon_gender_ratio' in df.columns:\n",
    "                corr = df['gender_sentiment_ratio'].corr(df['lexicon_gender_ratio'])\n",
    "                correlations['Gender Sentiment vs Lexicon'] = round(corr, 3)\n",
    "            \n",
    "            validation_results['correlations'] = correlations\n",
    "            \n",
    "            # 2. Agreement analysis\n",
    "            if 'sentiment_classification' in df.columns and 'lexicon_gender_classification' in df.columns:\n",
    "                # Create agreement matrix\n",
    "                agreement_matrix = pd.crosstab(\n",
    "                    df['sentiment_classification'], \n",
    "                    df['lexicon_gender_classification']\n",
    "                )\n",
    "                validation_results['agreement_matrix'] = agreement_matrix\n",
    "                \n",
    "                # Calculate agreement percentage\n",
    "                # Convert to comparable categories\n",
    "                sentiment_positive = df['sentiment_classification'] == 'Positive'\n",
    "                lexicon_masculine = df['lexicon_gender_classification'] == 'Masculine-coded'\n",
    "                \n",
    "                sentiment_negative = df['sentiment_classification'] == 'Negative'\n",
    "                lexicon_feminine = df['lexicon_gender_classification'] == 'Feminine-coded'\n",
    "                \n",
    "                positive_agreement = (sentiment_positive & lexicon_masculine).sum()\n",
    "                negative_agreement = (sentiment_negative & lexicon_feminine).sum()\n",
    "                total_agreement = positive_agreement + negative_agreement\n",
    "                agreement_percentage = (total_agreement / len(df)) * 100\n",
    "                \n",
    "                validation_results['agreement_percentage'] = round(agreement_percentage, 1)\n",
    "            \n",
    "            # 3. Outlier analysis - jobs with conflicting scores\n",
    "            conflicting_jobs = []\n",
    "            \n",
    "            if ('vader_compound' in df.columns and 'lexicon_gender_ratio' in df.columns):\n",
    "                # Find jobs with positive sentiment but high masculine coding\n",
    "                positive_sentiment_masculine = df[\n",
    "                    (df['vader_compound'] > 0.1) & \n",
    "                    (df['lexicon_gender_ratio'] > 2.0)\n",
    "                ]\n",
    "                \n",
    "                # Find jobs with negative sentiment but high feminine coding\n",
    "                negative_sentiment_feminine = df[\n",
    "                    (df['vader_compound'] < -0.1) & \n",
    "                    (df['lexicon_gender_ratio'] < -2.0)\n",
    "                ]\n",
    "                \n",
    "                validation_results['conflicting_positive_masculine'] = len(positive_sentiment_masculine)\n",
    "                validation_results['conflicting_negative_feminine'] = len(negative_sentiment_feminine)\n",
    "            \n",
    "            # Print validation results\n",
    "            print(f\"ðŸ“ˆ Correlation Analysis:\")\n",
    "            for metric, corr in correlations.items():\n",
    "                print(f\"   {metric}: {corr}\")\n",
    "            \n",
    "            if 'agreement_percentage' in validation_results:\n",
    "                print(f\"\\nðŸŽ¯ Agreement Analysis:\")\n",
    "                print(f\"   Overall Agreement: {validation_results['agreement_percentage']}%\")\n",
    "            \n",
    "            print(f\"\\nâš ï¸  Conflicting Cases:\")\n",
    "            print(f\"   Positive sentiment + Masculine coding: {validation_results.get('conflicting_positive_masculine', 0)}\")\n",
    "            print(f\"   Negative sentiment + Feminine coding: {validation_results.get('conflicting_negative_feminine', 0)}\")\n",
    "        \n",
    "        else:\n",
    "            print(\"âš ï¸  No lexicon scores found. Skipping validation analysis.\")\n",
    "            validation_results['message'] = \"No lexicon data available for validation\"\n",
    "        \n",
    "        return validation_results\n",
    "\n",
    "    def generate_sentiment_summary(self, df):\n",
    "        \"\"\"Generate comprehensive sentiment analysis summary\"\"\"\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*70)\n",
    "        print(\"SENTIMENT ANALYSIS SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Basic sentiment distribution\n",
    "        if 'sentiment_classification' in df.columns:\n",
    "            print(f\"ðŸ“Š Sentiment Classification:\")\n",
    "            sentiment_counts = df['sentiment_classification'].value_counts()\n",
    "            for sentiment, count in sentiment_counts.items():\n",
    "                percentage = (count / len(df)) * 100\n",
    "                print(f\"   {sentiment}: {count:,} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Average sentiment scores\n",
    "        sentiment_metrics = ['sentiment_polarity', 'vader_compound', 'or_sentiment_ratio']\n",
    "        available_metrics = [col for col in sentiment_metrics if col in df.columns]\n",
    "        \n",
    "        if available_metrics:\n",
    "            print(f\"\\nðŸ“ˆ Average Sentiment Scores:\")\n",
    "            for metric in available_metrics:\n",
    "                avg_score = df[metric].mean()\n",
    "                print(f\"   {metric}: {avg_score:.3f}\")\n",
    "        \n",
    "        # OR-specific sentiment\n",
    "        if 'or_positive_score' in df.columns and 'or_negative_score' in df.columns:\n",
    "            print(f\"\\nðŸŽ¯ OR-Specific Sentiment:\")\n",
    "            print(f\"   Average positive score: {df['or_positive_score'].mean():.2f}%\")\n",
    "            print(f\"   Average negative score: {df['or_negative_score'].mean():.2f}%\")\n",
    "            print(f\"   Average sentiment ratio: {df['or_sentiment_ratio'].mean():.2f}\")\n",
    "        \n",
    "        # Gender sentiment patterns\n",
    "        if 'gender_sentiment_ratio' in df.columns:\n",
    "            print(f\"\\nâš–ï¸  Gender Sentiment Patterns:\")\n",
    "            print(f\"   Average gender sentiment ratio: {df['gender_sentiment_ratio'].mean():.2f}\")\n",
    "            \n",
    "            masculine_dominant = (df['gender_sentiment_ratio'] > 10).sum()\n",
    "            feminine_dominant = (df['gender_sentiment_ratio'] < -10).sum()\n",
    "            \n",
    "            print(f\"   Jobs with masculine sentiment patterns: {masculine_dominant}\")\n",
    "            print(f\"   Jobs with feminine sentiment patterns: {feminine_dominant}\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to add sentiment analysis to existing lexicon-scored dataset\"\"\"\n",
    "    \n",
    "    # File path to your existing dataset\n",
    "    input_path = r\"C:\\Users\\HP\\OneDrive - University of Southampton\\Documents\\Dissertation Project - Marwa Ashfaq\\Dataset\\Final Dataset.xlsx\"\n",
    "    \n",
    "    # Output path (same file, updated)\n",
    "    output_path = r\"C:\\Users\\HP\\OneDrive - University of Southampton\\Documents\\Dissertation Project - Marwa Ashfaq\\Dataset\\Final Dataset.xlsx\"\n",
    "    \n",
    "    try:\n",
    "        print(\"=\"*70)\n",
    "        print(\"OR JOBS SENTIMENT ANALYSIS - COMPLEMENTING LEXICON SCORES\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"This will add comprehensive sentiment analysis to your existing\")\n",
    "        print(\"lexicon-scored dataset for validation and deeper insights.\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Read existing dataset\n",
    "        print(f\"ðŸ“ Reading existing dataset...\")\n",
    "        df = pd.read_excel(input_path, sheet_name='All_Jobs_Combined')\n",
    "        print(f\"âœ… Loaded {len(df):,} jobs with {len(df.columns)} columns\")\n",
    "        \n",
    "        # Initialize sentiment analyzer\n",
    "        analyzer = ORJobSentimentAnalyzer()\n",
    "        \n",
    "        # Add sentiment analysis\n",
    "        df_with_sentiment = analyzer.add_sentiment_analysis_to_dataset(df)\n",
    "        \n",
    "        # Create validation analysis\n",
    "        validation_results = analyzer.create_validation_analysis(df_with_sentiment)\n",
    "        \n",
    "        # Generate summary\n",
    "        final_df = analyzer.generate_sentiment_summary(df_with_sentiment)\n",
    "        \n",
    "        # Save updated dataset\n",
    "        print(f\"\\nðŸ’¾ Saving updated dataset with sentiment analysis...\")\n",
    "        \n",
    "        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "            # Main dataset with both lexicon and sentiment\n",
    "            final_df.to_excel(writer, sheet_name='Jobs_Lexicon_and_Sentiment', index=False)\n",
    "            \n",
    "            # Validation analysis\n",
    "            if validation_results and 'correlations' in validation_results:\n",
    "                validation_df = pd.DataFrame([\n",
    "                    ['Metric', 'Correlation'],\n",
    "                    *[[k, v] for k, v in validation_results['correlations'].items()]\n",
    "                ])\n",
    "                validation_df.to_excel(writer, sheet_name='Validation_Analysis', index=False, header=False)\n",
    "            \n",
    "            # Sentiment summary\n",
    "            if 'sentiment_classification' in final_df.columns:\n",
    "                sentiment_summary = final_df['sentiment_classification'].value_counts().reset_index()\n",
    "                sentiment_summary.columns = ['Sentiment', 'Count']\n",
    "                sentiment_summary['Percentage'] = (sentiment_summary['Count'] / len(final_df) * 100).round(1)\n",
    "                sentiment_summary.to_excel(writer, sheet_name='Sentiment_Summary', index=False)\n",
    "            \n",
    "            # Combined analysis (lexicon + sentiment)\n",
    "            if 'lexicon_gender_classification' in final_df.columns and 'sentiment_classification' in final_df.columns:\n",
    "                combined_analysis = pd.crosstab(\n",
    "                    final_df['lexicon_gender_classification'],\n",
    "                    final_df['sentiment_classification']\n",
    "                ).reset_index()\n",
    "                combined_analysis.to_excel(writer, sheet_name='Lexicon_vs_Sentiment', index=False)\n",
    "        \n",
    "        print(f\"âœ… Updated dataset saved to: {output_path}\")\n",
    "        print(f\"ðŸ“Š Total columns now: {len(final_df.columns)}\")\n",
    "        \n",
    "        # Show sample of new sentiment columns\n",
    "        sentiment_cols = [col for col in final_df.columns if 'sentiment' in col.lower() or 'vader' in col.lower()]\n",
    "        if sentiment_cols:\n",
    "            print(f\"\\nðŸ“‹ New Sentiment Columns Added:\")\n",
    "            for col in sentiment_cols[:10]:  # Show first 10\n",
    "                print(f\"   {col}\")\n",
    "        \n",
    "        print(f\"\\nðŸŽ‰ SENTIMENT ANALYSIS COMPLETE!\")\n",
    "        print(f\"Your dataset now has both lexicon and sentiment analysis for\")\n",
    "        print(f\"comprehensive validation and deeper insights into gendered language!\")\n",
    "        \n",
    "        return final_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check and install required packages\n",
    "    print(\"Checking required packages...\")\n",
    "    \n",
    "    packages_to_install = []\n",
    "    \n",
    "    try:\n",
    "        import textblob\n",
    "    except ImportError:\n",
    "        packages_to_install.append(\"textblob\")\n",
    "    \n",
    "    try:\n",
    "        import vaderSentiment\n",
    "    except ImportError:\n",
    "        packages_to_install.append(\"vaderSentiment\")\n",
    "    \n",
    "    if packages_to_install:\n",
    "        print(f\"âŒ Missing packages: {', '.join(packages_to_install)}\")\n",
    "        print(\"Please run these commands in your terminal:\")\n",
    "        print(\"   pip install textblob vaderSentiment nltk\")\n",
    "        print(\"   python -m textblob.download_corpora\")\n",
    "        print(\"\\nThen run this script again.\")\n",
    "    else:\n",
    "        print(\"âœ… All required packages available\")\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b04527-0055-42e9-b9e2-eb322754a8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
